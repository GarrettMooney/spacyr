% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/parse.R
\name{tokens_tag}
\alias{tokens_tag}
\title{tag parts of speech using spaCy via rPython}
\usage{
tokens_tag(tokens, tagset = c("google", "penn"))
}
\arguments{
\item{tokens}{a tokenizedText_spacyr object}

\item{tagset}{character label for the tagset to use, either \code{"google"} 
or \code{"penn"} to use the simplified Google tagset, or the more detailed 
scheme from the Penn Treebank.}
}
\value{
a tokenized text object with tags
}
\description{
Tokenize a text using spaCy and tag the tokens with part-of-speech tags. 
Options exist for using either the Google or Penn tagsets. See 
\url{http://spacy.io}.
}
\examples{
\donttest{
txt <- c(text1 = "This is the first sentence.\\nHere is the second sentence.", 
         text2 = "This is the second document.")
results <- spacy_parse(txt)
tokens <- tokens(results)
tokens_with_tag <- tokens_tag(tokens)
}
}

