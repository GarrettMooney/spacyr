% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/spacy_tokenize.R
\name{spacy_tokenize}
\alias{spacy_tokenize}
\title{Just tokenize text with spaCy}
\usage{
spacy_tokenize(x, remove_punct = FALSE, multithread = TRUE, ...)
}
\arguments{
\item{x}{a character object, a \pkg{quanteda} corpus, or a TIF-compliant
corpus data.frame (see \url{https://github.com/ropensci/tif})}

\item{remove_punct}{remove puctuation tokens.}

\item{multithread}{logical; If true, the processing is parallelized using pipe 
functionality of spacy (\url{https://spacy.io/api/pipe}).}

\item{...}{not used directly}
}
\value{
a \code{data.frame} of tokenized, parsed, and annotated tokens
}
\description{
Just tokenize text with spaCy
}
\examples{
\donttest{
spacy_initialize()
txt <- "And now for something completely different."
spacy_tokenize(txt)

txt2 <- c(doc1 = "The fast cat catches mice.\\\\nThe quick brown dog jumped.", 
          doc2 = "This is the second document.",
          doc3 = "This is a \\\\\\"quoted\\\\\\" text." )
spacy_tokenize(txt2)
}
}
